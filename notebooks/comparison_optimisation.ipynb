{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a559fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "import hdbscan\n",
    "from itertools import product\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    "    adjusted_rand_score,\n",
    "    adjusted_mutual_info_score,\n",
    "    homogeneity_score,\n",
    "    completeness_score,\n",
    "    v_measure_score\n",
    ")\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c859aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_mouse_path(state_params, width, height):\n",
    "    if \"initial_bias\" in state_params:\n",
    "        bias = state_params[\"initial_bias\"]\n",
    "        bias_std = state_params.get(\"bias_std\", 50)\n",
    "        x = int(np.clip(np.random.normal(bias[0], bias_std), 0, width-1))\n",
    "        y = int(np.clip(np.random.normal(bias[1], bias_std), 0, height-1))\n",
    "    else:\n",
    "        x = np.random.randint(0, width)\n",
    "        y = np.random.randint(0, height)\n",
    "    \n",
    "    angle = np.random.uniform(0, 2 * np.pi)\n",
    "    events = []\n",
    "    \n",
    "    for _ in range(state_params[\"path_length\"]):\n",
    "        events.append((x, y))\n",
    "        angle += np.random.normal(0, state_params.get(\"angle_variance\", 0.1))\n",
    "        if np.random.rand() < state_params.get(\"drift_probability\", 0.05):\n",
    "            if \"drift_target\" in state_params:\n",
    "                target_x, target_y = state_params[\"drift_target\"]\n",
    "                desired_angle = np.arctan2(target_y - y, target_x - x)\n",
    "                angle = (angle + desired_angle) / 2\n",
    "        step = np.random.uniform(state_params.get(\"step_min\", 1), state_params.get(\"step_max\", 10))\n",
    "        x += int(step * np.cos(angle))\n",
    "        y += int(step * np.sin(angle))\n",
    "        \n",
    "        if \"confined_region\" in state_params:\n",
    "            region = state_params[\"confined_region\"]\n",
    "            x = max(region[0], min(x, region[2]))\n",
    "            y = max(region[1], min(y, region[3]))\n",
    "        else:\n",
    "            x = max(0, min(x, width-1))\n",
    "            y = max(0, min(y, height-1))\n",
    "    return events\n",
    " \n",
    "def simulate_minute_heatmap(state_params, width, height, scale):\n",
    "    all_events = []\n",
    "    for _ in range(state_params[\"num_paths\"]):\n",
    "        events = simulate_mouse_path(state_params, width, height)\n",
    "        all_events.extend(events)\n",
    "    \n",
    "    out_width = width // scale\n",
    "    out_height = height // scale\n",
    "    heatmap = np.zeros((out_height, out_width), dtype=float)\n",
    "    \n",
    "    for (x, y) in all_events:\n",
    "        bin_x = int(x // scale)\n",
    "        bin_y = int(y // scale)\n",
    "        if 0 <= bin_x < out_width and 0 <= bin_y < out_height:\n",
    "            heatmap[bin_y, bin_x] += 1\n",
    "    \n",
    "    max_val = heatmap.max()\n",
    "    if max_val > 0:\n",
    "        heatmap = heatmap / max_val\n",
    "    return heatmap\n",
    "\n",
    "def simulate_heatmap_series(total_minutes, timeline, width, height, scale):\n",
    "    series = []\n",
    "    for minute in range(total_minutes):\n",
    "        state_label = None\n",
    "        state_params = None\n",
    "        for (start, end, label, params) in timeline:\n",
    "            if start <= minute < end:\n",
    "                state_label = label\n",
    "                state_params = params\n",
    "                break\n",
    "        if state_params is None:\n",
    "            state_params = {\"num_paths\": 10, \"path_length\": 500, \"angle_variance\": 0.1,\n",
    "                            \"step_min\": 1, \"step_max\": 8, \"drift_probability\": 0.05}\n",
    "            state_label = \"default\"\n",
    "        heatmap = simulate_minute_heatmap(state_params, width, height, scale)\n",
    "        series.append((minute, state_label, heatmap))\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7926b7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minute 0: State A\n",
      "Minute 1: State A\n",
      "Minute 2: State A\n",
      "Minute 3: State A\n",
      "Minute 4: State A\n",
      "Minute 5: State A\n",
      "Minute 6: State A\n",
      "Minute 7: State A\n",
      "Minute 8: State A\n",
      "Minute 9: State A\n",
      "Minute 10: State A\n",
      "Minute 11: State A\n",
      "Minute 12: State A\n",
      "Minute 13: State A\n",
      "Minute 14: State A\n",
      "Minute 15: State A\n",
      "Minute 16: State A\n",
      "Minute 17: State A\n",
      "Minute 18: State A\n",
      "Minute 19: State A\n",
      "Minute 20: State A\n",
      "Minute 21: State A\n",
      "Minute 22: State A\n",
      "Minute 23: State A\n",
      "Minute 24: State A\n",
      "Minute 25: State A\n",
      "Minute 26: State A\n",
      "Minute 27: State A\n",
      "Minute 28: State A\n",
      "Minute 29: State A\n",
      "Minute 30: State B\n",
      "Minute 31: State B\n",
      "Minute 32: State B\n",
      "Minute 33: State B\n",
      "Minute 34: State B\n",
      "Minute 35: State B\n",
      "Minute 36: State B\n",
      "Minute 37: State B\n",
      "Minute 38: State B\n",
      "Minute 39: State B\n",
      "Minute 40: State B\n",
      "Minute 41: State B\n",
      "Minute 42: State B\n",
      "Minute 43: State B\n",
      "Minute 44: State B\n",
      "Minute 45: State B\n",
      "Minute 46: State B\n",
      "Minute 47: State B\n",
      "Minute 48: State B\n",
      "Minute 49: State B\n",
      "Minute 50: State B\n",
      "Minute 51: State B\n",
      "Minute 52: State B\n",
      "Minute 53: State B\n",
      "Minute 54: State B\n",
      "Minute 55: State B\n",
      "Minute 56: State B\n",
      "Minute 57: State B\n",
      "Minute 58: State B\n",
      "Minute 59: State B\n",
      "Minute 60: State B\n",
      "Minute 61: State B\n",
      "Minute 62: State B\n",
      "Minute 63: State B\n",
      "Minute 64: State B\n",
      "Minute 65: State B\n",
      "Minute 66: State B\n",
      "Minute 67: State B\n",
      "Minute 68: State B\n",
      "Minute 69: State B\n",
      "Minute 70: State B\n",
      "Minute 71: State B\n",
      "Minute 72: State B\n",
      "Minute 73: State B\n",
      "Minute 74: State B\n",
      "Minute 75: State B\n",
      "Minute 76: State B\n",
      "Minute 77: State B\n",
      "Minute 78: State B\n",
      "Minute 79: State B\n",
      "Minute 80: State B\n",
      "Minute 81: State B\n",
      "Minute 82: State B\n",
      "Minute 83: State B\n",
      "Minute 84: State B\n",
      "Minute 85: State B\n",
      "Minute 86: State B\n",
      "Minute 87: State B\n",
      "Minute 88: State B\n",
      "Minute 89: State B\n",
      "Minute 90: State C\n",
      "Minute 91: State C\n",
      "Minute 92: State C\n",
      "Minute 93: State C\n",
      "Minute 94: State C\n",
      "Minute 95: State C\n",
      "Minute 96: State C\n",
      "Minute 97: State C\n",
      "Minute 98: State C\n",
      "Minute 99: State C\n",
      "Minute 100: State C\n",
      "Minute 101: State C\n",
      "Minute 102: State C\n",
      "Minute 103: State C\n",
      "Minute 104: State C\n",
      "Minute 105: State C\n",
      "Minute 106: State C\n",
      "Minute 107: State C\n",
      "Minute 108: State C\n",
      "Minute 109: State C\n",
      "Minute 110: State B\n",
      "Minute 111: State B\n",
      "Minute 112: State B\n",
      "Minute 113: State B\n",
      "Minute 114: State B\n",
      "Minute 115: State B\n",
      "Minute 116: State B\n",
      "Minute 117: State B\n",
      "Minute 118: State B\n",
      "Minute 119: State B\n",
      "Minute 120: State B\n",
      "Minute 121: State B\n",
      "Minute 122: State B\n",
      "Minute 123: State B\n",
      "Minute 124: State B\n",
      "Minute 125: State E\n",
      "Minute 126: State E\n",
      "Minute 127: State E\n",
      "Minute 128: State E\n",
      "Minute 129: State E\n",
      "Minute 130: State E\n",
      "Minute 131: State E\n",
      "Minute 132: State E\n",
      "Minute 133: State E\n",
      "Minute 134: State E\n",
      "Minute 135: State E\n",
      "Minute 136: State E\n",
      "Minute 137: State E\n",
      "Minute 138: State E\n",
      "Minute 139: State E\n",
      "Minute 140: State E\n",
      "Minute 141: State E\n",
      "Minute 142: State E\n",
      "Minute 143: State E\n",
      "Minute 144: State E\n",
      "Minute 145: State E\n",
      "Minute 146: State E\n",
      "Minute 147: State E\n",
      "Minute 148: State E\n",
      "Minute 149: State E\n",
      "Minute 150: State E\n",
      "Minute 151: State E\n",
      "Minute 152: State E\n",
      "Minute 153: State E\n",
      "Minute 154: State E\n",
      "Minute 155: State E\n",
      "Minute 156: State E\n",
      "Minute 157: State E\n",
      "Minute 158: State E\n",
      "Minute 159: State E\n",
      "Minute 160: State C\n",
      "Minute 161: State C\n",
      "Minute 162: State C\n",
      "Minute 163: State C\n",
      "Minute 164: State C\n",
      "Minute 165: State C\n",
      "Minute 166: State C\n",
      "Minute 167: State C\n",
      "Minute 168: State C\n",
      "Minute 169: State C\n",
      "Minute 170: State C\n",
      "Minute 171: State C\n",
      "Minute 172: State C\n",
      "Minute 173: State C\n",
      "Minute 174: State C\n",
      "Minute 175: State C\n",
      "Minute 176: State C\n",
      "Minute 177: State C\n",
      "Minute 178: State C\n",
      "Minute 179: State C\n",
      "Minute 180: State C\n",
      "Minute 181: State C\n",
      "Minute 182: State C\n",
      "Minute 183: State C\n",
      "Minute 184: State C\n",
      "Minute 185: State C\n",
      "Minute 186: State C\n",
      "Minute 187: State C\n",
      "Minute 188: State C\n",
      "Minute 189: State C\n",
      "Minute 190: State B\n",
      "Minute 191: State B\n",
      "Minute 192: State B\n",
      "Minute 193: State B\n",
      "Minute 194: State B\n",
      "Minute 195: State B\n",
      "Minute 196: State B\n",
      "Minute 197: State B\n",
      "Minute 198: State B\n",
      "Minute 199: State B\n",
      "Minute 200: State B\n",
      "Minute 201: State B\n",
      "Minute 202: State B\n",
      "Minute 203: State B\n",
      "Minute 204: State B\n",
      "Minute 205: State B\n",
      "Minute 206: State B\n",
      "Minute 207: State B\n",
      "Minute 208: State B\n",
      "Minute 209: State B\n",
      "Minute 210: State E\n",
      "Minute 211: State E\n",
      "Minute 212: State E\n",
      "Minute 213: State E\n",
      "Minute 214: State E\n",
      "Minute 215: State E\n",
      "Minute 216: State E\n",
      "Minute 217: State E\n",
      "Minute 218: State E\n",
      "Minute 219: State E\n",
      "Minute 220: State E\n",
      "Minute 221: State E\n",
      "Minute 222: State E\n",
      "Minute 223: State E\n",
      "Minute 224: State E\n",
      "Minute 225: State E\n",
      "Minute 226: State E\n",
      "Minute 227: State E\n",
      "Minute 228: State E\n",
      "Minute 229: State E\n",
      "Minute 230: State E\n",
      "Minute 231: State E\n",
      "Minute 232: State E\n",
      "Minute 233: State E\n",
      "Minute 234: State E\n",
      "Minute 235: State E\n",
      "Minute 236: State E\n",
      "Minute 237: State E\n",
      "Minute 238: State E\n",
      "Minute 239: State E\n",
      "Minute 240: State B\n",
      "Minute 241: State B\n",
      "Minute 242: State B\n",
      "Minute 243: State B\n",
      "Minute 244: State B\n",
      "Minute 245: State B\n",
      "Minute 246: State B\n",
      "Minute 247: State B\n",
      "Minute 248: State B\n",
      "Minute 249: State B\n",
      "Minute 250: State C\n",
      "Minute 251: State C\n",
      "Minute 252: State C\n",
      "Minute 253: State C\n",
      "Minute 254: State C\n",
      "Minute 255: State C\n",
      "Minute 256: State C\n",
      "Minute 257: State C\n",
      "Minute 258: State C\n",
      "Minute 259: State C\n",
      "Minute 260: State C\n",
      "Minute 261: State C\n",
      "Minute 262: State C\n",
      "Minute 263: State C\n",
      "Minute 264: State C\n",
      "Minute 265: State C\n",
      "Minute 266: State C\n",
      "Minute 267: State C\n",
      "Minute 268: State C\n",
      "Minute 269: State C\n",
      "Minute 270: State C\n",
      "Minute 271: State C\n",
      "Minute 272: State C\n",
      "Minute 273: State C\n",
      "Minute 274: State C\n",
      "Minute 275: State F\n",
      "Minute 276: State F\n",
      "Minute 277: State F\n",
      "Minute 278: State F\n",
      "Minute 279: State F\n",
      "Minute 280: State F\n",
      "Minute 281: State F\n",
      "Minute 282: State F\n",
      "Minute 283: State F\n",
      "Minute 284: State F\n",
      "Minute 285: State F\n",
      "Minute 286: State F\n",
      "Minute 287: State F\n",
      "Minute 288: State F\n",
      "Minute 289: State F\n",
      "Minute 290: State A\n",
      "Minute 291: State A\n",
      "Minute 292: State A\n",
      "Minute 293: State A\n",
      "Minute 294: State A\n",
      "Minute 295: State A\n",
      "Minute 296: State A\n",
      "Minute 297: State A\n",
      "Minute 298: State A\n",
      "Minute 299: State A\n",
      "Minute 300: State A\n",
      "Minute 301: State A\n",
      "Minute 302: State A\n",
      "Minute 303: State A\n",
      "Minute 304: State A\n",
      "Minute 305: State A\n",
      "Minute 306: State A\n",
      "Minute 307: State A\n",
      "Minute 308: State A\n",
      "Minute 309: State A\n",
      "Minute 310: State E\n",
      "Minute 311: State E\n",
      "Minute 312: State E\n",
      "Minute 313: State E\n",
      "Minute 314: State E\n",
      "Minute 315: State E\n",
      "Minute 316: State E\n",
      "Minute 317: State E\n",
      "Minute 318: State E\n",
      "Minute 319: State E\n",
      "Minute 320: State E\n",
      "Minute 321: State E\n",
      "Minute 322: State E\n",
      "Minute 323: State E\n",
      "Minute 324: State E\n",
      "Minute 325: State E\n",
      "Minute 326: State E\n",
      "Minute 327: State E\n",
      "Minute 328: State E\n",
      "Minute 329: State E\n",
      "Minute 330: State D\n",
      "Minute 331: State D\n",
      "Minute 332: State D\n",
      "Minute 333: State D\n",
      "Minute 334: State D\n",
      "Minute 335: State D\n",
      "Minute 336: State D\n",
      "Minute 337: State D\n",
      "Minute 338: State D\n",
      "Minute 339: State D\n",
      "Minute 340: State D\n",
      "Minute 341: State D\n",
      "Minute 342: State D\n",
      "Minute 343: State D\n",
      "Minute 344: State D\n",
      "Minute 345: State D\n",
      "Minute 346: State D\n",
      "Minute 347: State D\n",
      "Minute 348: State D\n",
      "Minute 349: State D\n",
      "Minute 350: State D\n",
      "Minute 351: State D\n",
      "Minute 352: State D\n",
      "Minute 353: State D\n",
      "Minute 354: State D\n",
      "Minute 355: State D\n",
      "Minute 356: State D\n",
      "Minute 357: State D\n",
      "Minute 358: State D\n",
      "Minute 359: State D\n"
     ]
    }
   ],
   "source": [
    "width, height = 2560, 1440\n",
    "scale = 40\n",
    "\n",
    "\n",
    "state_A = {\n",
    "        \"num_paths\": 20,\n",
    "        \"path_length\": 800,\n",
    "        \"angle_variance\": 0.2,\n",
    "        \"step_min\": 2,\n",
    "        \"step_max\": 8,\n",
    "        \"drift_probability\": 0.1,\n",
    "        \"drift_target\": (width // 2, height // 2),\n",
    "        \"initial_bias\": (width // 2, height // 2),\n",
    "        \"bias_std\": 100\n",
    "}\n",
    "\n",
    "state_B = {\n",
    "        \"num_paths\": 15,\n",
    "        \"path_length\": 1000,\n",
    "        \"angle_variance\": 0.1,\n",
    "        \"step_min\": 1,\n",
    "        \"step_max\": 5,\n",
    "        \"drift_probability\": 0.05,\n",
    "        \"confined_region\": (width // 4, height // 4, width // 2, height // 2),\n",
    "        \"initial_bias\": (width // 3, height // 3),\n",
    "        \"bias_std\": 50\n",
    "}\n",
    "\n",
    "state_C = {\n",
    "        \"num_paths\": 25,\n",
    "        \"path_length\": 600,\n",
    "        \"angle_variance\": 0.5,\n",
    "        \"step_min\": 3,\n",
    "        \"step_max\": 12,\n",
    "        \"drift_probability\": 0.2,\n",
    "        \"drift_target\": (int(width * 0.75), int(height * 0.75)),\n",
    "        \"initial_bias\": (width // 2, height // 2),\n",
    "        \"bias_std\": 150\n",
    "}\n",
    "\n",
    "state_D = {\n",
    "        \"num_paths\": 10,\n",
    "        \"path_length\": 400,\n",
    "        \"angle_variance\": 0.3,\n",
    "        \"step_min\": 2,\n",
    "        \"step_max\": 6,\n",
    "        \"drift_probability\": 0.1,\n",
    "        \"drift_target\": (width // 4, height // 4),\n",
    "        \"initial_bias\": (width // 4, height // 4),\n",
    "        \"bias_std\": 80\n",
    "}\n",
    "\n",
    "state_E = {\n",
    "        \"num_paths\": 50,\n",
    "        \"path_length\": 500,\n",
    "        \"angle_variance\": 0.8,\n",
    "        \"step_min\": 3,\n",
    "        \"step_max\": 4,\n",
    "        \"drift_probability\": 0.3,\n",
    "        \"drift_target\": (int(width * 0.35), int(height * 0.25)),\n",
    "        \"initial_bias\": (width // 2, height // 2),\n",
    "        \"bias_std\": 50\n",
    "}\n",
    "\n",
    "state_F = {\n",
    "        \"num_paths\": 30,\n",
    "        \"path_length\": 700,\n",
    "        \"angle_variance\": 0.4,\n",
    "        \"step_min\": 1,\n",
    "        \"step_max\": 2,\n",
    "        \"drift_probability\": 0.15,\n",
    "        \"drift_target\": (int(width * 0.8), int(height * 0.8)),\n",
    "        \"initial_bias\": (width // 2, height // 2),\n",
    "        \"bias_std\": 100\n",
    "}\n",
    "\n",
    "timeline = [\n",
    "        (0, 30, \"State A\", state_A),\n",
    "        (30, 90, \"State B\", state_B),\n",
    "        (90, 110, \"State C\", state_C),\n",
    "        (110, 125, \"State B\", state_B),\n",
    "        (125, 160, \"State E\", state_A),\n",
    "        (160, 190, \"State C\", state_C),\n",
    "        (190, 210, \"State B\", state_B),\n",
    "        (210, 240, \"State E\", state_B),\n",
    "        # Anomaly detection states\n",
    "        (240, 250, \"State B\", state_B),\n",
    "        (250, 275, \"State C\", state_C),\n",
    "        (275, 290, \"State F\", state_F), # anomaly\n",
    "        (290, 310, \"State A\", state_A),\n",
    "        (310, 330, \"State E\", state_E),\n",
    "        (330, 360, \"State D\", state_D), # anomaly\n",
    "]\n",
    "\n",
    "total_minutes = 360\n",
    "series = simulate_heatmap_series(total_minutes, timeline, width, height, scale)\n",
    "\n",
    "for minute, state_label, _ in series:\n",
    "        print(f\"Minute {minute}: {state_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc940785",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps = [heatmap.flatten() for _, _, heatmap in series]\n",
    "minutes = np.array([minute for minute, _, _ in series])\n",
    "true_state_labels = [state_label for _, state_label, _ in series]\n",
    "label_mapping = {label: idx for idx, label in enumerate(sorted(set(true_state_labels)))}\n",
    "true_labels = np.array([label_mapping[s] for s in true_state_labels])\n",
    "X = np.array(heatmaps)\n",
    "pca = PCA(n_components=10)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "train_mask = minutes < 240\n",
    "test_mask = minutes >= 240\n",
    "\n",
    "X_train = X_reduced[train_mask]\n",
    "X_test = X_reduced[test_mask]\n",
    "true_states_test = np.array(true_state_labels)[test_mask]\n",
    "anomaly_states = {\"State F\", \"State D\"}\n",
    "y_true = np.array([1 if s in anomaly_states else 0 for s in true_states_test])\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "db = DBSCAN(eps=0.7, min_samples=5).fit(X_train)\n",
    "core_samples = X_train[db.core_sample_indices_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe9976d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NearestNeighbour: Best F1=0.818 with params {'eps': 0.4}\n",
      "OneClassSVM: Best F1=0.818 with params {'nu': 0.001, 'kernel': 'linear', 'gamma': 'scale'}\n",
      "IsolationForest: Best F1=0.531 with params {'n_estimators': 25, 'contamination': 0.05}\n"
     ]
    }
   ],
   "source": [
    "def detect_nn_core(core_samples, X_test, eps):\n",
    "    nn = NearestNeighbors(radius=eps).fit(core_samples)\n",
    "    neighbors = nn.radius_neighbors(X_test, return_distance=False)\n",
    "    # 0 = normal, 1 = anomaly\n",
    "    return np.array([0 if len(nbrs) > 0 else 1 for nbrs in neighbors])\n",
    "\n",
    "def detect_ocsvm_core(core_samples, X_test, nu, kernel, gamma):\n",
    "    ocsvm = OneClassSVM(nu=nu, kernel=kernel, gamma=gamma).fit(core_samples)\n",
    "    preds = ocsvm.predict(X_test)  # +1 normal, -1 anomaly\n",
    "    return np.array([0 if p == 1 else 1 for p in preds])\n",
    "\n",
    "def detect_iforest_core(core_samples, X_test, n_estimators, contamination):\n",
    "    iso = IsolationForest(n_estimators=n_estimators, contamination=contamination).fit(core_samples)\n",
    "    preds = iso.predict(X_test)  # +1 normal, -1 anomaly\n",
    "    return np.array([0 if p == 1 else 1 for p in preds])\n",
    "\n",
    "def optimize_comparison_core(core_samples, X_test, y_true, methods, primary_metric='f1'):\n",
    "    metric_fns = {\n",
    "        'accuracy': accuracy_score,\n",
    "        'precision': lambda yt, yp: precision_score(yt, yp, pos_label=1),\n",
    "        'recall': lambda yt, yp: recall_score(yt, yp, pos_label=1),\n",
    "        'f1': lambda yt, yp: f1_score(yt, yp, pos_label=1)\n",
    "    }\n",
    "    if primary_metric not in metric_fns:\n",
    "        raise ValueError(f\"Unsupported metric {primary_metric}\")\n",
    "    primary_fn = metric_fns[primary_metric]\n",
    "    \n",
    "    results = {}\n",
    "    for name, cfg in methods.items():\n",
    "        fn = cfg['func']\n",
    "        hyper = cfg.get('hyperparams', {})\n",
    "        param_names, param_values = zip(*hyper.items()) if hyper else ([], [])\n",
    "        \n",
    "        best = {'params': None, 'score': -np.inf, 'metrics': {}}\n",
    "        for vals in product(*param_values):\n",
    "            params = dict(zip(param_names, vals))\n",
    "            try:\n",
    "                y_pred = fn(core_samples, X_test, **params)\n",
    "            except Exception:\n",
    "                continue\n",
    "            if len(y_pred) != len(y_true):\n",
    "                continue\n",
    "            score = primary_fn(y_true, y_pred)\n",
    "            if score > best['score']:\n",
    "                best['score'] = score\n",
    "                best['params'] = params\n",
    "                best['metrics'] = {\n",
    "                    'accuracy': accuracy_score(y_true, y_pred),\n",
    "                    'precision': precision_score(y_true, y_pred, pos_label=1),\n",
    "                    'recall': recall_score(y_true, y_pred, pos_label=1),\n",
    "                    'f1': f1_score(y_true, y_pred, pos_label=1)\n",
    "                }\n",
    "        results[name] = best\n",
    "    return results\n",
    "\n",
    "\n",
    "methods = {\n",
    "    'NearestNeighbour': {\n",
    "        'func': detect_nn_core,\n",
    "        'hyperparams': {\n",
    "            'eps': [0.2, 0.3, 0.4, 0.5, 0.7, 0.9],\n",
    "        }\n",
    "    },\n",
    "    'OneClassSVM': {\n",
    "        'func': detect_ocsvm_core,\n",
    "        'hyperparams': {\n",
    "            'nu': [0.001, 0.01, 0.05, 0.1, 0.5],\n",
    "            'kernel': ['rbf', 'linear', 'poly', 'sigmoid'],\n",
    "            'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
    "        }\n",
    "    },\n",
    "    'IsolationForest': {\n",
    "        'func': detect_iforest_core,\n",
    "        'hyperparams': {\n",
    "            'n_estimators': [25, 50, 100, 150, 200],\n",
    "            'contamination': [0.001, 0.01, 0.05, 0.1]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "results = optimize_comparison_core(core_samples, X_test, y_true, methods, primary_metric='f1')\n",
    "\n",
    "for name, res in results.items():\n",
    "    print(f\"{name}: Best F1={res['metrics']['f1']:.3f} with params {res['params']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39fe4454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"NearestNeighbour\": {\n",
      "        \"params\": {\n",
      "            \"eps\": 0.4\n",
      "        },\n",
      "        \"score\": 0.8181818181818182,\n",
      "        \"metrics\": {\n",
      "            \"accuracy\": 0.8333333333333334,\n",
      "            \"precision\": 0.6923076923076923,\n",
      "            \"recall\": 1.0,\n",
      "            \"f1\": 0.8181818181818182\n",
      "        }\n",
      "    },\n",
      "    \"OneClassSVM\": {\n",
      "        \"params\": {\n",
      "            \"nu\": 0.001,\n",
      "            \"kernel\": \"linear\",\n",
      "            \"gamma\": \"scale\"\n",
      "        },\n",
      "        \"score\": 0.8181818181818182,\n",
      "        \"metrics\": {\n",
      "            \"accuracy\": 0.8333333333333334,\n",
      "            \"precision\": 0.6923076923076923,\n",
      "            \"recall\": 1.0,\n",
      "            \"f1\": 0.8181818181818182\n",
      "        }\n",
      "    },\n",
      "    \"IsolationForest\": {\n",
      "        \"params\": {\n",
      "            \"n_estimators\": 25,\n",
      "            \"contamination\": 0.05\n",
      "        },\n",
      "        \"score\": 0.53125,\n",
      "        \"metrics\": {\n",
      "            \"accuracy\": 0.75,\n",
      "            \"precision\": 0.8947368421052632,\n",
      "            \"recall\": 0.37777777777777777,\n",
      "            \"f1\": 0.53125\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(results, indent=4, default=str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly-DYcyjKpA-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
